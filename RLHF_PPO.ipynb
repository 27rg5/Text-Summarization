{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"execution":{"iopub.execute_input":"2024-06-28T05:02:13.493962Z","iopub.status.busy":"2024-06-28T05:02:13.493602Z","iopub.status.idle":"2024-06-28T05:04:30.995472Z","shell.execute_reply":"2024-06-28T05:04:30.994343Z","shell.execute_reply.started":"2024-06-28T05:02:13.493930Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.11.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.41.2)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\n","Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.30.1)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.3.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Looking in indexes: https://pypi.org/simple/\n","Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.1)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Collecting trl\n","  Downloading trl-0.9.4-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.1.2)\n","Requirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl) (4.41.2)\n","Requirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.4)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.30.1)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (2.19.2)\n","Collecting tyro>=0.5.11 (from trl)\n","  Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2024.3.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.23.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (4.66.4)\n","Collecting docstring-parser>=0.16 (from tyro>=0.5.11->trl)\n","  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.0)\n","Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n","  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl) (5.9.3)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (2.2.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.9.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (2024.2.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.4)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n","Downloading trl-0.9.4-py3-none-any.whl (226 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.8.5-py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n","Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Installing collected packages: shtab, docstring-parser, tyro, trl\n","  Attempting uninstall: docstring-parser\n","    Found existing installation: docstring-parser 0.15\n","    Uninstalling docstring-parser-0.15:\n","      Successfully uninstalled docstring-parser-0.15\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed docstring-parser-0.16 shtab-1.7.1 trl-0.9.4 tyro-0.8.5\n","Collecting langchain\n","  Downloading langchain-0.2.6-py3-none-any.whl.metadata (7.0 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n","Collecting langchain-core<0.3.0,>=0.2.10 (from langchain)\n","  Downloading langchain_core-0.2.10-py3-none-any.whl.metadata (6.0 kB)\n","Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n","  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.82-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\n","Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.10->langchain)\n","  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (2.4)\n","Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.2.10-py3-none-any.whl (332 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.82-py3-none-any.whl (127 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain-core, langchain-text-splitters, langchain\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: orjson\n","    Found existing installation: orjson 3.9.10\n","    Uninstalling orjson-3.9.10:\n","      Successfully uninstalled orjson-3.9.10\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.4.1 requires cubinlinker, which is not installed.\n","cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.4.1 requires ptxcompiler, which is not installed.\n","cuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","keras-cv 0.9.0 requires keras-core, which is not installed.\n","keras-nlp 0.12.1 requires keras-core, which is not installed.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\n","cudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n","distributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n","jupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n","rapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n","rapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\n","spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langchain-0.2.6 langchain-core-0.2.10 langchain-text-splitters-0.2.2 langsmith-0.1.82 orjson-3.10.5 packaging-24.1\n","Collecting langchain_community\n","  Downloading langchain_community-0.2.6-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.1)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.6)\n","Requirement already satisfied: langchain<0.3.0,>=0.2.6 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.6)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.10)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.82)\n","Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.2.3)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.6->langchain_community) (0.2.2)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.6->langchain_community) (2.5.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_community) (24.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.9.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain_community) (2.4)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain_community) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain_community) (2.14.6)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n","Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: langchain_community\n","Successfully installed langchain_community-0.2.6\n","Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=5a65f608d1f2740b969a412b4ca9ab629f66c9a4e1b05cb3ae107c72a8d05725\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n","Collecting py7zr\n","  Downloading py7zr-0.21.0-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\n","Collecting pycryptodomex>=3.16.0 (from py7zr)\n","  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting pyzstd>=0.15.9 (from py7zr)\n","  Downloading pyzstd-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n","Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n","  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n","Collecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n","  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Collecting multivolumefile>=0.2.3 (from py7zr)\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n","Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n","  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Requirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.0)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\n","Downloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyzstd-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.8/413.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n","Successfully installed inflate64-1.0.0 multivolumefile-0.2.3 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pyzstd-0.16.0\n","Collecting evaluate\n","  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.19.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.1)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.23.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (24.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.2\n","Collecting detoxify\n","  Downloading detoxify-0.5.2-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from detoxify) (4.41.2)\n","Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from detoxify) (2.1.2)\n","Requirement already satisfied: sentencepiece>=0.1.94 in /opt/conda/lib/python3.10/site-packages (from detoxify) (0.2.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->detoxify) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->detoxify) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->detoxify) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->detoxify) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->detoxify) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->detoxify) (2024.3.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers->detoxify) (0.23.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers->detoxify) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->detoxify) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->detoxify) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->detoxify) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->detoxify) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->detoxify) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->detoxify) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->detoxify) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->detoxify) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->detoxify) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->detoxify) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->detoxify) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->detoxify) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.0->detoxify) (1.3.0)\n","Downloading detoxify-0.5.2-py3-none-any.whl (12 kB)\n","Installing collected packages: detoxify\n","Successfully installed detoxify-0.5.2\n"]}],"source":["!pip install peft\n","!pip install accelerate\n","!pip install -i https://pypi.org/simple/ bitsandbytes\n","!pip install trl\n","!pip install langchain\n","!pip install langchain_community\n","!pip install rouge-score\n","!pip install py7zr\n","!pip install evaluate\n","!pip install detoxify"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T05:04:30.997586Z","iopub.status.busy":"2024-06-28T05:04:30.997276Z","iopub.status.idle":"2024-06-28T05:04:48.725886Z","shell.execute_reply":"2024-06-28T05:04:48.724883Z","shell.execute_reply.started":"2024-06-28T05:04:30.997557Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-28 05:04:36.739632: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-28 05:04:36.739737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-28 05:04:36.849694: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["# Imports\n","import torch\n","from detoxify import Detoxify\n","from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback, AutoModelForSequenceClassification\n","from datasets import load_dataset, load_metric, concatenate_datasets, DatasetDict\n","from sklearn.model_selection import train_test_split\n","from peft import get_peft_model, PeftModel, PeftConfig, LoraConfig, TaskType\n","from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n","from langchain import PromptTemplate, LLMChain\n","from langchain.llms import HuggingFacePipeline\n","from tqdm import tqdm\n","from rouge_score import rouge_scorer\n","import numpy as np\n","from random import randrange\n","from evaluate import load\n","from trl.core import LengthSampler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T05:05:11.135927Z","iopub.status.busy":"2024-06-28T05:05:11.135234Z","iopub.status.idle":"2024-06-28T05:05:27.327697Z","shell.execute_reply":"2024-06-28T05:05:27.326885Z","shell.execute_reply.started":"2024-06-28T05:05:11.135895Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for samsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/samsum\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00a3929fde2b481383d26261e918b500","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/3.36k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d20351e8eca5482f8bf93b7768b34ca6","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/7.04k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e19dcfe71284a6e8915e745ae04bfac","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/2.94M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a57a4888d1947eabb6b733b8c36b27c","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81d1a450c9dd4d14be7776357dada872","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"438dff9123ae4594bde788c075cce902","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a5d0c44afd244ceb9e83bd086f65a06","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aef15f4fd6604f7a95f91d88dbd54c3d","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3a4a89bfaae4a718dc0fe13679942ce","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d07d1c88389467c88fe24f67e7481d9","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06a2a91abc2442e3aa6f68667227b216","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a74d4a84ad0745a1af0ec6e787a47bad","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4114c587f9d9475d8e318716016856db","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/unitaryai/detoxify/releases/download/v0.1-alpha/toxic_original-c1212f89.ckpt\" to /root/.cache/torch/hub/checkpoints/toxic_original-c1212f89.ckpt\n","100%|██████████| 418M/418M [00:01<00:00, 302MB/s] \n","/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f36926725edd44dd9fcd9e7be1bbe598","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14d7cf40a93c4d0cb347802c9f902252","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bee6fa9253f94e38a7d853803864d347","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ede9d9303eef4fc0a55812fdc3bdb511","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = load_dataset(\"samsum\")\n","\n","model_name = \"google/flan-t5-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n","peft_model = PeftModel.from_pretrained(base_model, \n","                                       \"/kaggle/input/models/lora_model\", \n","                                       torch_dtype=torch.bfloat16,\n","                                       is_trainable=True)\n","\n","ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,                                                               \n","                                                               torch_dtype=torch.bfloat16,\n","                                                               is_trainable=True)\n","\n","reward_model = Detoxify('original')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T05:05:32.432109Z","iopub.status.busy":"2024-06-28T05:05:32.431616Z","iopub.status.idle":"2024-06-28T05:05:32.443519Z","shell.execute_reply":"2024-06-28T05:05:32.442350Z","shell.execute_reply.started":"2024-06-28T05:05:32.432065Z"},"trusted":true},"outputs":[],"source":["class SamsumDataset(Dataset):\n","    def __init__(self, dataset, tokenizer, max_length=512):\n","        self.dataset = dataset\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        item = self.dataset[idx]\n","        dialogue = item['dialogue']\n","        summary = item['summary']\n","        \n","        inputs = self.tokenizer(\"summarize: \" + dialogue, \n","                                truncation=True, \n","                                max_length=self.max_length, \n","                                return_tensors=\"pt\")\n","        \n","        return {\n","            \"input_ids\": inputs.input_ids.squeeze(),\n","            \"attention_mask\": inputs.attention_mask.squeeze(),\n","            \"query\": dialogue,\n","            \"summary\": summary\n","        }\n","\n","train_dataset = SamsumDataset(dataset['train'], tokenizer)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T05:05:45.742163Z","iopub.status.busy":"2024-06-28T05:05:45.741462Z","iopub.status.idle":"2024-06-28T05:05:45.747659Z","shell.execute_reply":"2024-06-28T05:05:45.746589Z","shell.execute_reply.started":"2024-06-28T05:05:45.742133Z"},"trusted":true},"outputs":[],"source":["def collator(data):\n","    return {key: [d[key] for d in data] for key in data[0]}\n","\n","# PPO Configuration\n","config = PPOConfig(\n","    model_name=model_name,\n","    learning_rate=1e-5,\n","    cliprange=0.1,\n","    mini_batch_size=4,\n","    batch_size=4,\n","    adap_kl_ctrl=True,  # Enable adaptive KL control\n","    init_kl_coef=0.2,  # Initial KL coefficient\n","    target_kl=0.01  # Target KL divergence\n",")\n","\n","ppo_trainer = PPOTrainer(\n","    config=config, \n","    model=ppo_model, \n","    tokenizer=tokenizer, \n","    dataset=train_dataset, \n","    data_collator=collator\n",")\n","\n","generation_kwargs = {\n","    \"min_length\": 5,\n","    \"max_new_tokens\": 100,\n","    \"top_k\": 0.0,\n","    \"top_p\": 1.0,\n","    \"do_sample\": True\n","}"]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-27T20:13:16.298247Z","iopub.status.busy":"2024-06-27T20:13:16.297874Z","iopub.status.idle":"2024-06-28T00:55:19.657542Z","shell.execute_reply":"2024-06-28T00:55:19.656496Z","shell.execute_reply.started":"2024-06-27T20:13:16.298216Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Training Progress:   0%|          | 1/3683 [00:06<7:03:29,  6.90s/it, kl=4.218, mean=0.199, adv_mean=0.000]"]},{"name":"stdout","output_type":"stream","text":["kl: 4.218080520629883\n","mean: 0.19915342330932617\n","advantages_mean: 2.0604074890684387e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:   0%|          | 3/3683 [00:17<5:51:10,  5.73s/it, kl=0.253, mean=0.379, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.44 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   1%|          | 20/3683 [01:40<5:27:04,  5.36s/it, kl=8.966, mean=-0.284, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.68 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   1%|          | 23/3683 [01:56<5:20:34,  5.26s/it, kl=5.071, mean=0.033, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.58 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   1%|          | 29/3683 [02:22<4:23:02,  4.32s/it, kl=-0.222, mean=0.522, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.04 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   1%|          | 32/3683 [02:36<4:35:38,  4.53s/it, kl=2.455, mean=0.239, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.14 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   1%|          | 40/3683 [03:14<5:18:01,  5.24s/it, kl=10.514, mean=-0.273, adv_mean=0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.76 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   1%|▏         | 53/3683 [04:11<3:49:59,  3.80s/it, kl=-0.982, mean=0.734, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.98 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   2%|▏         | 70/3683 [05:31<4:27:42,  4.45s/it, kl=-0.377, mean=0.499, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.47 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   2%|▏         | 80/3683 [06:21<4:58:50,  4.98s/it, kl=3.198, mean=0.276, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.11 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   2%|▏         | 90/3683 [07:13<5:52:03,  5.88s/it, kl=1.319, mean=0.380, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.13 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   3%|▎         | 97/3683 [07:46<4:49:41,  4.85s/it, kl=2.387, mean=0.408, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.84 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   3%|▎         | 101/3683 [08:07<5:14:38,  5.27s/it, kl=-0.203, mean=0.417, adv_mean=0.000]"]},{"name":"stdout","output_type":"stream","text":["kl: -0.20313525199890137\n","mean: 0.41730809211730957\n","advantages_mean: 0.0\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:   3%|▎         | 112/3683 [09:01<5:14:07,  5.28s/it, kl=4.662, mean=0.047, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.16 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   3%|▎         | 114/3683 [09:10<4:51:52,  4.91s/it, kl=3.002, mean=0.337, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.60 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   3%|▎         | 123/3683 [09:53<4:30:50,  4.56s/it, kl=0.721, mean=0.699, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.25 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   4%|▎         | 132/3683 [10:38<5:11:05,  5.26s/it, kl=2.094, mean=0.314, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.71 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   4%|▎         | 134/3683 [10:45<4:15:42,  4.32s/it, kl=0.757, mean=0.525, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.41 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   4%|▎         | 137/3683 [10:58<4:12:53,  4.28s/it, kl=2.964, mean=0.296, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.00 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   4%|▍         | 159/3683 [12:43<4:36:38,  4.71s/it, kl=-0.458, mean=0.605, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.35 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   5%|▍         | 171/3683 [13:39<4:47:49,  4.92s/it, kl=1.334, mean=0.466, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.24 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   5%|▌         | 187/3683 [14:54<4:37:55,  4.77s/it, kl=-0.588, mean=0.808, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.31 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   5%|▌         | 201/3683 [16:02<4:36:49,  4.77s/it, kl=-0.081, mean=0.604, adv_mean=0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: -0.08143731951713562\n","mean: 0.6041287779808044\n","advantages_mean: 6.079673653403006e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:   6%|▌         | 214/3683 [16:58<4:02:27,  4.19s/it, kl=4.975, mean=0.080, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.27 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   6%|▌         | 228/3683 [18:03<4:17:41,  4.47s/it, kl=0.475, mean=0.662, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.97 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   7%|▋         | 240/3683 [19:02<4:55:40,  5.15s/it, kl=1.355, mean=0.505, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.39 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   7%|▋         | 246/3683 [19:31<4:37:18,  4.84s/it, kl=3.644, mean=0.322, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.60 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   8%|▊         | 285/3683 [22:38<4:56:44,  5.24s/it, kl=0.835, mean=0.535, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.14 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   8%|▊         | 287/3683 [22:48<4:57:43,  5.26s/it, kl=1.335, mean=0.517, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.31 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   8%|▊         | 290/3683 [23:04<4:57:31,  5.26s/it, kl=5.734, mean=0.118, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.88 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   8%|▊         | 301/3683 [23:58<4:29:52,  4.79s/it, kl=3.952, mean=0.173, adv_mean=0.000]  "]},{"name":"stdout","output_type":"stream","text":["kl: 3.951982021331787\n","mean: 0.1729649305343628\n","advantages_mean: 7.0123111761688506e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:   9%|▊         | 314/3683 [24:58<4:15:01,  4.54s/it, kl=2.068, mean=0.434, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.57 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:   9%|▉         | 344/3683 [27:12<4:45:34,  5.13s/it, kl=2.403, mean=0.382, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.19 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  10%|▉         | 350/3683 [27:41<4:21:37,  4.71s/it, kl=3.430, mean=0.125, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.92 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  10%|▉         | 353/3683 [27:53<4:12:41,  4.55s/it, kl=0.439, mean=0.610, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.91 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  10%|▉         | 367/3683 [28:54<3:27:24,  3.75s/it, kl=3.377, mean=0.309, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.12 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  10%|█         | 372/3683 [29:13<3:20:07,  3.63s/it, kl=2.486, mean=0.368, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.47 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  10%|█         | 376/3683 [29:32<3:53:59,  4.25s/it, kl=3.502, mean=0.424, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.37 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  11%|█         | 395/3683 [30:59<4:16:56,  4.69s/it, kl=4.046, mean=0.270, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.13 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  11%|█         | 398/3683 [31:11<3:49:06,  4.18s/it, kl=0.435, mean=0.638, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.21 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  11%|█         | 401/3683 [31:23<3:40:01,  4.02s/it, kl=3.184, mean=0.412, adv_mean=0.000]  "]},{"name":"stdout","output_type":"stream","text":["kl: 3.183598756790161\n","mean: 0.4124032258987427\n","advantages_mean: 0.0\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  12%|█▏        | 436/3683 [34:07<4:02:14,  4.48s/it, kl=4.985, mean=0.275, adv_mean=-0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  12%|█▏        | 444/3683 [34:41<3:49:40,  4.25s/it, kl=4.198, mean=0.068, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.17 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  12%|█▏        | 453/3683 [35:24<4:54:50,  5.48s/it, kl=2.168, mean=0.517, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.01 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  12%|█▏        | 460/3683 [36:01<4:34:23,  5.11s/it, kl=5.276, mean=0.109, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  13%|█▎        | 479/3683 [37:27<4:31:39,  5.09s/it, kl=5.460, mean=0.227, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.26 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  13%|█▎        | 480/3683 [37:30<4:05:45,  4.60s/it, kl=-1.261, mean=0.762, adv_mean=0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.65 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  13%|█▎        | 483/3683 [37:45<4:11:29,  4.72s/it, kl=3.772, mean=0.308, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.56 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  13%|█▎        | 495/3683 [38:37<3:19:22,  3.75s/it, kl=1.428, mean=0.390, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.96 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  14%|█▎        | 501/3683 [39:01<3:33:20,  4.02s/it, kl=0.104, mean=0.768, adv_mean=0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 0.10406327247619629\n","mean: 0.767870306968689\n","advantages_mean: 5.5493977413334505e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.17 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  14%|█▍        | 512/3683 [39:49<3:30:34,  3.98s/it, kl=1.097, mean=0.555, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.08 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  14%|█▍        | 523/3683 [40:42<3:55:55,  4.48s/it, kl=0.590, mean=0.630, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.86 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  15%|█▍        | 545/3683 [42:31<4:11:14,  4.80s/it, kl=-0.293, mean=0.565, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.46 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  15%|█▍        | 550/3683 [42:53<4:01:30,  4.63s/it, kl=-0.891, mean=0.746, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.08 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  15%|█▌        | 558/3683 [43:30<4:17:25,  4.94s/it, kl=5.560, mean=0.227, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.40 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  15%|█▌        | 568/3683 [44:20<4:16:35,  4.94s/it, kl=5.491, mean=0.053, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.17 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  16%|█▌        | 577/3683 [45:00<3:38:12,  4.22s/it, kl=3.378, mean=0.373, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.81 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  16%|█▌        | 580/3683 [45:13<3:27:00,  4.00s/it, kl=-0.815, mean=0.856, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.22 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  16%|█▌        | 592/3683 [46:08<4:00:25,  4.67s/it, kl=3.872, mean=0.227, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.69 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  16%|█▋        | 601/3683 [46:52<4:25:29,  5.17s/it, kl=3.502, mean=0.494, adv_mean=0.000]  "]},{"name":"stdout","output_type":"stream","text":["kl: 3.5022389888763428\n","mean: 0.4943574368953705\n","advantages_mean: 0.0\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  16%|█▋        | 607/3683 [47:19<3:58:07,  4.64s/it, kl=2.243, mean=0.558, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.42 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  17%|█▋        | 615/3683 [47:54<3:59:49,  4.69s/it, kl=2.971, mean=0.508, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -5.09 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  17%|█▋        | 621/3683 [48:20<3:27:08,  4.06s/it, kl=2.521, mean=0.591, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.77 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  17%|█▋        | 626/3683 [48:44<4:12:03,  4.95s/it, kl=4.004, mean=0.503, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.04 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  18%|█▊        | 652/3683 [50:39<3:29:33,  4.15s/it, kl=2.807, mean=0.536, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.90 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  19%|█▉        | 701/3683 [54:29<3:46:23,  4.56s/it, kl=5.666, mean=0.056, adv_mean=0.000]   "]},{"name":"stdout","output_type":"stream","text":["kl: 5.66552734375\n","mean: 0.056435614824295044\n","advantages_mean: 9.482556961870614e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  19%|█▉        | 702/3683 [54:33<3:39:34,  4.42s/it, kl=1.904, mean=0.394, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.45 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  19%|█▉        | 718/3683 [55:46<4:09:16,  5.04s/it, kl=4.705, mean=0.243, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.45 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  20%|█▉        | 727/3683 [56:29<3:30:16,  4.27s/it, kl=6.315, mean=0.036, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.07 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  20%|█▉        | 735/3683 [57:06<3:22:54,  4.13s/it, kl=2.408, mean=0.459, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.82 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  21%|██        | 779/3683 [1:00:16<4:21:45,  5.41s/it, kl=5.796, mean=0.324, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.06 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  21%|██▏       | 785/3683 [1:00:45<3:49:12,  4.75s/it, kl=1.795, mean=0.626, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.89 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  22%|██▏       | 798/3683 [1:01:50<3:44:14,  4.66s/it, kl=4.841, mean=0.375, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.39 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  22%|██▏       | 801/3683 [1:02:03<3:39:12,  4.56s/it, kl=6.218, mean=0.268, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 6.218156337738037\n","mean: 0.26785075664520264\n","advantages_mean: -1.1573717983992537e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  22%|██▏       | 813/3683 [1:02:59<3:58:17,  4.98s/it, kl=3.318, mean=0.486, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.03 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  22%|██▏       | 815/3683 [1:03:09<3:53:50,  4.89s/it, kl=5.936, mean=-0.083, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.92 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  23%|██▎       | 829/3683 [1:04:13<3:28:06,  4.38s/it, kl=0.064, mean=0.856, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.53 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  23%|██▎       | 859/3683 [1:06:36<3:57:06,  5.04s/it, kl=-1.008, mean=0.736, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.11 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  23%|██▎       | 863/3683 [1:06:56<3:56:56,  5.04s/it, kl=0.089, mean=0.794, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.48 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  24%|██▍       | 901/3683 [1:09:51<3:29:54,  4.53s/it, kl=4.570, mean=0.276, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 4.569610595703125\n","mean: 0.27609097957611084\n","advantages_mean: -7.947286384535346e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  25%|██▍       | 908/3683 [1:10:26<4:03:02,  5.25s/it, kl=4.032, mean=0.280, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.27 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  27%|██▋       | 1001/3683 [1:17:56<2:56:47,  3.95s/it, kl=0.581, mean=0.750, adv_mean=-0.000]"]},{"name":"stdout","output_type":"stream","text":["kl: 0.5812541842460632\n","mean: 0.7504050731658936\n","advantages_mean: -1.9542505391711984e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  27%|██▋       | 1005/3683 [1:18:11<2:53:36,  3.89s/it, kl=2.320, mean=0.441, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.91 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  28%|██▊       | 1017/3683 [1:19:01<2:55:08,  3.94s/it, kl=4.519, mean=0.472, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.21 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  28%|██▊       | 1025/3683 [1:19:35<3:05:21,  4.18s/it, kl=2.277, mean=0.562, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.95 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  29%|██▉       | 1064/3683 [1:22:24<3:17:24,  4.52s/it, kl=1.468, mean=0.627, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.83 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  30%|██▉       | 1101/3683 [1:25:13<3:12:40,  4.48s/it, kl=3.314, mean=0.458, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 3.314171314239502\n","mean: 0.4576910138130188\n","advantages_mean: -4.4151589051466544e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  30%|██▉       | 1104/3683 [1:25:29<3:31:27,  4.92s/it, kl=1.572, mean=0.604, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.52 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  31%|███       | 1135/3683 [1:27:47<3:07:45,  4.42s/it, kl=2.561, mean=0.498, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.36 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  32%|███▏      | 1171/3683 [1:30:28<2:45:06,  3.94s/it, kl=2.329, mean=0.442, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.18 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  32%|███▏      | 1175/3683 [1:30:44<2:40:37,  3.84s/it, kl=5.708, mean=0.149, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.20 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  32%|███▏      | 1195/3683 [1:32:20<3:33:34,  5.15s/it, kl=5.691, mean=0.244, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.55 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  33%|███▎      | 1201/3683 [1:32:46<3:11:57,  4.64s/it, kl=0.170, mean=0.704, adv_mean=0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 0.17043375968933105\n","mean: 0.7041835784912109\n","advantages_mean: 3.116582902862319e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.05 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  33%|███▎      | 1206/3683 [1:33:08<3:22:23,  4.90s/it, kl=4.750, mean=0.386, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.63 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  34%|███▎      | 1238/3683 [1:35:32<2:43:11,  4.00s/it, kl=-0.652, mean=0.871, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -5.46 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  34%|███▍      | 1267/3683 [1:37:44<3:04:35,  4.58s/it, kl=2.978, mean=0.547, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.45 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  35%|███▌      | 1301/3683 [1:40:23<3:05:22,  4.67s/it, kl=2.453, mean=0.476, adv_mean=0.000]  "]},{"name":"stdout","output_type":"stream","text":["kl: 2.453484535217285\n","mean: 0.4760223627090454\n","advantages_mean: 8.90199203240627e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  35%|███▌      | 1303/3683 [1:40:32<2:59:48,  4.53s/it, kl=0.320, mean=0.850, adv_mean=0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.73 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  35%|███▌      | 1305/3683 [1:40:43<3:27:06,  5.23s/it, kl=0.880, mean=0.669, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.54 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  35%|███▌      | 1307/3683 [1:40:54<3:19:29,  5.04s/it, kl=-0.310, mean=0.822, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.82 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  36%|███▌      | 1312/3683 [1:41:16<2:59:19,  4.54s/it, kl=0.419, mean=0.721, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.25 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  36%|███▌      | 1320/3683 [1:41:50<2:32:56,  3.88s/it, kl=1.498, mean=0.867, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.75 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  36%|███▌      | 1331/3683 [1:42:42<3:09:42,  4.84s/it, kl=0.651, mean=0.607, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.50 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  36%|███▌      | 1332/3683 [1:42:45<2:54:47,  4.46s/it, kl=-1.498, mean=0.933, adv_mean=0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.48 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  37%|███▋      | 1356/3683 [1:44:43<3:09:54,  4.90s/it, kl=7.107, mean=0.156, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  38%|███▊      | 1400/3683 [1:48:11<2:45:55,  4.36s/it, kl=3.771, mean=0.397, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.29 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  38%|███▊      | 1401/3683 [1:48:15<2:40:27,  4.22s/it, kl=-2.292, mean=0.985, adv_mean=0.000]"]},{"name":"stdout","output_type":"stream","text":["kl: -2.291853666305542\n","mean: 0.9850170612335205\n","advantages_mean: 2.1457671550706436e-07\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  38%|███▊      | 1407/3683 [1:48:40<2:41:47,  4.27s/it, kl=5.623, mean=0.194, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.65 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  39%|███▉      | 1438/3683 [1:50:55<2:42:58,  4.36s/it, kl=3.080, mean=0.501, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.06 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  39%|███▉      | 1441/3683 [1:51:12<3:21:33,  5.39s/it, kl=3.424, mean=0.371, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.56 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  40%|███▉      | 1467/3683 [1:53:08<2:54:04,  4.71s/it, kl=7.519, mean=0.139, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.30 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  40%|███▉      | 1468/3683 [1:53:12<2:45:14,  4.48s/it, kl=-1.299, mean=0.921, adv_mean=0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.67 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  40%|████      | 1483/3683 [1:54:12<2:15:25,  3.69s/it, kl=1.657, mean=0.740, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.16 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  41%|████      | 1501/3683 [1:55:32<2:35:50,  4.29s/it, kl=2.757, mean=0.464, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 2.7571959495544434\n","mean: 0.46447545289993286\n","advantages_mean: -3.4304832308151845e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  42%|████▏     | 1533/3683 [1:57:55<2:27:13,  4.11s/it, kl=-1.358, mean=0.943, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.64 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  42%|████▏     | 1549/3683 [1:59:07<2:14:33,  3.78s/it, kl=-0.474, mean=0.834, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.55 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  42%|████▏     | 1558/3683 [1:59:44<2:08:49,  3.64s/it, kl=0.567, mean=0.822, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.62 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  43%|████▎     | 1570/3683 [2:00:39<2:40:44,  4.56s/it, kl=2.864, mean=0.568, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.04 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  43%|████▎     | 1601/3683 [2:02:56<2:25:02,  4.18s/it, kl=1.974, mean=0.761, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 1.9741158485412598\n","mean: 0.7607730031013489\n","advantages_mean: -2.4082684735304838e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  45%|████▍     | 1655/3683 [2:06:59<2:30:37,  4.46s/it, kl=2.707, mean=0.463, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.06 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  46%|████▌     | 1678/3683 [2:08:42<2:31:46,  4.54s/it, kl=1.118, mean=0.760, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.02 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  46%|████▌     | 1681/3683 [2:08:54<2:17:36,  4.12s/it, kl=6.073, mean=0.300, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.38 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  46%|████▌     | 1701/3683 [2:10:22<2:34:14,  4.67s/it, kl=1.805, mean=0.678, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 1.8049073219299316\n","mean: 0.6781737208366394\n","advantages_mean: -3.1044087300813317e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  47%|████▋     | 1723/3683 [2:12:01<2:34:28,  4.73s/it, kl=-2.064, mean=0.879, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.98 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  47%|████▋     | 1728/3683 [2:12:27<2:37:04,  4.82s/it, kl=5.068, mean=0.271, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.28 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  47%|████▋     | 1748/3683 [2:14:00<2:16:23,  4.23s/it, kl=2.686, mean=0.471, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.00 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  49%|████▊     | 1793/3683 [2:17:26<2:10:55,  4.16s/it, kl=0.538, mean=0.821, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.09 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  49%|████▉     | 1801/3683 [2:18:05<2:25:33,  4.64s/it, kl=0.771, mean=0.662, adv_mean=0.000]  "]},{"name":"stdout","output_type":"stream","text":["kl: 0.7708817720413208\n","mean: 0.662341833114624\n","advantages_mean: 3.804551784725163e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  52%|█████▏    | 1901/3683 [2:25:40<2:09:20,  4.36s/it, kl=5.987, mean=0.166, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 5.987425804138184\n","mean: 0.1663094013929367\n","advantages_mean: -8.61753868264259e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  54%|█████▎    | 1977/3683 [2:31:43<2:16:56,  4.82s/it, kl=4.179, mean=0.396, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.08 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  54%|█████▍    | 2001/3683 [2:33:30<2:37:12,  5.61s/it, kl=2.958, mean=0.605, adv_mean=0.000]  "]},{"name":"stdout","output_type":"stream","text":["kl: 2.958388328552246\n","mean: 0.6052960157394409\n","advantages_mean: 2.9253812705576365e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  55%|█████▍    | 2020/3683 [2:34:57<2:04:31,  4.49s/it, kl=7.278, mean=0.027, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.23 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  55%|█████▌    | 2027/3683 [2:35:23<1:46:02,  3.84s/it, kl=0.454, mean=0.817, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.78 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  55%|█████▌    | 2043/3683 [2:36:31<1:49:37,  4.01s/it, kl=3.824, mean=0.442, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.51 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  57%|█████▋    | 2093/3683 [2:40:16<2:14:52,  5.09s/it, kl=-0.265, mean=0.744, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.76 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  57%|█████▋    | 2101/3683 [2:40:54<2:00:21,  4.56s/it, kl=2.266, mean=0.478, adv_mean=0.000]  "]},{"name":"stdout","output_type":"stream","text":["kl: 2.2661378383636475\n","mean: 0.4778139591217041\n","advantages_mean: 4.11066514161007e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  59%|█████▊    | 2163/3683 [2:45:39<2:12:59,  5.25s/it, kl=-0.204, mean=0.844, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.40 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  60%|█████▉    | 2201/3683 [2:48:29<2:06:23,  5.12s/it, kl=0.248, mean=0.706, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 0.24833029508590698\n","mean: 0.7056378126144409\n","advantages_mean: -8.514949634275126e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  60%|█████▉    | 2202/3683 [2:48:34<2:02:29,  4.96s/it, kl=3.545, mean=0.587, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.26 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  60%|██████    | 2215/3683 [2:49:30<1:34:53,  3.88s/it, kl=1.674, mean=0.756, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.85 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  60%|██████    | 2222/3683 [2:50:03<1:52:57,  4.64s/it, kl=3.614, mean=0.381, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.36 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  61%|██████    | 2241/3683 [2:51:27<1:38:38,  4.10s/it, kl=-0.874, mean=0.991, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.94 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  62%|██████▏   | 2294/3683 [2:55:36<1:53:48,  4.92s/it, kl=2.913, mean=0.451, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.69 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  62%|██████▏   | 2301/3683 [2:56:10<2:00:28,  5.23s/it, kl=2.013, mean=0.613, adv_mean=0.000]  "]},{"name":"stdout","output_type":"stream","text":["kl: 2.0127639770507812\n","mean: 0.6130272746086121\n","advantages_mean: 1.3099922036019507e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  63%|██████▎   | 2326/3683 [2:58:09<1:50:46,  4.90s/it, kl=8.422, mean=0.021, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.30 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  64%|██████▍   | 2348/3683 [2:59:41<1:31:08,  4.10s/it, kl=1.613, mean=0.696, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.46 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  64%|██████▍   | 2371/3683 [3:01:34<1:35:32,  4.37s/it, kl=0.214, mean=0.852, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.22 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  65%|██████▌   | 2401/3683 [3:03:49<1:45:01,  4.92s/it, kl=3.181, mean=0.664, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 3.1812314987182617\n","mean: 0.6644951105117798\n","advantages_mean: -3.5321270352994816e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  67%|██████▋   | 2451/3683 [3:07:33<1:28:42,  4.32s/it, kl=-1.462, mean=0.979, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.79 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  67%|██████▋   | 2454/3683 [3:07:46<1:30:37,  4.42s/it, kl=1.645, mean=0.649, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.32 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  68%|██████▊   | 2499/3683 [3:11:24<1:34:00,  4.76s/it, kl=3.983, mean=0.610, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.19 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  68%|██████▊   | 2501/3683 [3:11:35<1:41:12,  5.14s/it, kl=1.974, mean=0.698, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 1.9737858772277832\n","mean: 0.6977442502975464\n","advantages_mean: -5.960465010446114e-09\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  68%|██████▊   | 2507/3683 [3:12:04<1:37:06,  4.95s/it, kl=-1.203, mean=0.805, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.01 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  68%|██████▊   | 2516/3683 [3:12:50<1:50:13,  5.67s/it, kl=8.355, mean=0.324, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.80 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  71%|███████   | 2601/3683 [3:19:23<1:28:12,  4.89s/it, kl=-0.631, mean=0.892, adv_mean=-0.000]"]},{"name":"stdout","output_type":"stream","text":["kl: -0.6314919590950012\n","mean: 0.8918336629867554\n","advantages_mean: -5.3589495507821994e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  71%|███████   | 2604/3683 [3:19:38<1:30:38,  5.04s/it, kl=3.172, mean=0.669, adv_mean=-0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.59 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  73%|███████▎  | 2684/3683 [3:25:40<1:20:37,  4.84s/it, kl=0.474, mean=0.769, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.23 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  73%|███████▎  | 2701/3683 [3:26:57<1:12:43,  4.44s/it, kl=1.722, mean=0.609, adv_mean=0.000]  "]},{"name":"stdout","output_type":"stream","text":["kl: 1.7221572399139404\n","mean: 0.6090301275253296\n","advantages_mean: 2.4543089338635582e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.40 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  74%|███████▍  | 2717/3683 [3:28:05<1:12:36,  4.51s/it, kl=1.419, mean=0.797, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.35 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  76%|███████▌  | 2801/3683 [3:34:22<1:06:46,  4.54s/it, kl=1.380, mean=0.759, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 1.3800276517868042\n","mean: 0.7588981986045837\n","advantages_mean: -2.504397045299811e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  76%|███████▋  | 2810/3683 [3:35:03<1:09:14,  4.76s/it, kl=3.221, mean=0.483, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.02 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  77%|███████▋  | 2820/3683 [3:35:57<1:20:42,  5.61s/it, kl=1.026, mean=0.761, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.35 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  78%|███████▊  | 2860/3683 [3:39:08<54:43,  3.99s/it, kl=5.160, mean=0.416, adv_mean=-0.000]   /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.18 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  79%|███████▉  | 2901/3683 [3:42:13<53:35,  4.11s/it, kl=3.380, mean=0.501, adv_mean=-0.000]   "]},{"name":"stdout","output_type":"stream","text":["kl: 3.3797945976257324\n","mean: 0.500562310218811\n","advantages_mean: -1.0145471129874295e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  79%|███████▉  | 2919/3683 [3:43:37<57:44,  4.53s/it, kl=0.392, mean=0.796, adv_mean=-0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.58 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  80%|███████▉  | 2942/3683 [3:45:23<54:23,  4.40s/it, kl=0.064, mean=0.842, adv_mean=0.000]    /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.66 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  81%|████████  | 2975/3683 [3:47:48<46:06,  3.91s/it, kl=3.546, mean=0.585, adv_mean=-0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.49 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  81%|████████  | 2979/3683 [3:48:12<1:04:04,  5.46s/it, kl=3.543, mean=0.544, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.81 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  81%|████████  | 2980/3683 [3:48:17<1:01:47,  5.27s/it, kl=-2.812, mean=1.039, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.70 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  81%|████████▏ | 3001/3683 [3:49:49<45:23,  3.99s/it, kl=0.408, mean=0.851, adv_mean=0.000]    "]},{"name":"stdout","output_type":"stream","text":["kl: 0.4083307981491089\n","mean: 0.8506069183349609\n","advantages_mean: 2.8610228852699038e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  83%|████████▎ | 3064/3683 [3:54:38<45:45,  4.44s/it, kl=4.843, mean=0.348, adv_mean=0.000]   /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.61 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  84%|████████▍ | 3087/3683 [3:56:29<44:10,  4.45s/it, kl=-0.391, mean=0.902, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.51 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  84%|████████▍ | 3101/3683 [3:57:31<44:22,  4.57s/it, kl=-1.693, mean=0.826, adv_mean=-0.000]"]},{"name":"stdout","output_type":"stream","text":["kl: -1.6930044889450073\n","mean: 0.8256033658981323\n","advantages_mean: -2.6181478318676454e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  85%|████████▍ | 3116/3683 [3:58:45<44:11,  4.68s/it, kl=2.475, mean=0.529, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.83 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  87%|████████▋ | 3201/3683 [4:05:15<38:09,  4.75s/it, kl=4.574, mean=0.491, adv_mean=0.000]  "]},{"name":"stdout","output_type":"stream","text":["kl: 4.573596954345703\n","mean: 0.49078986048698425\n","advantages_mean: 3.434843875993465e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  90%|████████▉ | 3301/3683 [4:12:51<29:06,  4.57s/it, kl=1.931, mean=0.785, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 1.931232213973999\n","mean: 0.7845461368560791\n","advantages_mean: -2.3841858265427618e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  92%|█████████▏| 3401/3683 [4:20:30<19:01,  4.05s/it, kl=4.426, mean=0.639, adv_mean=0.000]  "]},{"name":"stdout","output_type":"stream","text":["kl: 4.425582408905029\n","mean: 0.6385164260864258\n","advantages_mean: 1.7103939597973294e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  93%|█████████▎| 3413/3683 [4:21:27<20:37,  4.58s/it, kl=-1.171, mean=0.847, adv_mean=0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.54 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  95%|█████████▌| 3501/3683 [4:28:00<15:01,  4.95s/it, kl=2.137, mean=0.689, adv_mean=-0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 2.1366782188415527\n","mean: 0.6892489194869995\n","advantages_mean: -9.691811797551964e-10\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress:  95%|█████████▌| 3515/3683 [4:29:05<12:18,  4.40s/it, kl=0.638, mean=0.805, adv_mean=0.000] /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.49 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  96%|█████████▌| 3522/3683 [4:29:36<11:07,  4.15s/it, kl=3.523, mean=0.447, adv_mean=-0.000]/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.36 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  98%|█████████▊| 3597/3683 [4:35:15<07:22,  5.15s/it, kl=2.818, mean=0.663, adv_mean=0.000]  /opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.17 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n","  warnings.warn(\n","Training Progress:  98%|█████████▊| 3601/3683 [4:35:36<06:50,  5.00s/it, kl=0.226, mean=0.911, adv_mean=0.000] "]},{"name":"stdout","output_type":"stream","text":["kl: 0.22613763809204102\n","mean: 0.9105694890022278\n","advantages_mean: 5.3551048040390015e-08\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress: 100%|██████████| 3683/3683 [4:42:03<00:00,  4.59s/it, kl=-0.497, mean=0.796, adv_mean=-0.000]\n"]}],"source":["steps_per_epoch = len(train_dataset) // config.batch_size\n","num_epochs = 1\n","max_ppo_steps = steps_per_epoch * num_epochs\n","\n","progress_bar = tqdm(total=max_ppo_steps, desc=\"Training Progress\", position=0, leave=True)\n","\n","for step, batch in enumerate(ppo_trainer.dataloader):\n","    if step >= max_ppo_steps:\n","        break   \n","\n","    prompt_tensors = batch[\"input_ids\"]\n","\n","    # Get response from PEFT LLM\n","    summary_tensors = []\n","\n","    for prompt_tensor in prompt_tensors:\n","        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n","        summary_tensors.append(summary.squeeze())\n","        \n","    batch[\"response\"] = [tokenizer.decode(r, skip_special_tokens=True) for r in summary_tensors]\n","\n","    # Compute reward outputs\n","    results = reward_model.predict(batch[\"response\"])\n","    rewards = [1 - results['toxicity'][i] for i in range(len(batch[\"response\"]))]\n","    reward_tensors = [torch.tensor(reward) for reward in rewards]\n","\n","    # Run PPO step\n","    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n","        \n","    ppo_trainer.log_stats(stats, batch, reward_tensors)\n","    \n","    progress_bar.set_postfix({\n","            'kl': f\"{stats['objective/kl']:.3f}\",\n","            'mean': f\"{stats['ppo/returns/mean']:.3f}\",\n","            'adv_mean': f\"{stats['ppo/policy/advantages_mean']:.3f}\"\n","        })\n","    \n","    if step%100 == 0:\n","        print(f'kl: {stats[\"objective/kl\"]}')\n","        print(f'mean: {stats[\"ppo/returns/mean\"]}')\n","        print(f'advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n","        print('-' * 100)\n","        \n","    # Update the progress bar\n","    progress_bar.update(1)\n","    \n","progress_bar.close()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T01:06:56.398086Z","iopub.status.busy":"2024-06-28T01:06:56.397703Z","iopub.status.idle":"2024-06-28T01:06:56.627331Z","shell.execute_reply":"2024-06-28T01:06:56.626592Z","shell.execute_reply.started":"2024-06-28T01:06:56.398056Z"},"trusted":true},"outputs":[],"source":["save_directory = \"/kaggle/working/final_model\"\n","ppo_trainer.model.save_pretrained(save_directory)\n","tokenizer.save_pretrained(save_directory)\n","torch.save(ppo_trainer.optimizer.state_dict(), \"/kaggle/working/optimizer.pt\")"]},{"cell_type":"markdown","metadata":{},"source":["# RLHF evaluation"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T05:06:07.117148Z","iopub.status.busy":"2024-06-28T05:06:07.116770Z","iopub.status.idle":"2024-06-28T05:06:07.347069Z","shell.execute_reply":"2024-06-28T05:06:07.346257Z","shell.execute_reply.started":"2024-06-28T05:06:07.117117Z"},"trusted":true},"outputs":[],"source":["peft_model_path = \"/kaggle/input/models/final_model\"\n","config = PeftConfig.from_pretrained(peft_model_path)\n","ppo_model = PeftModel.from_pretrained(base_model, peft_model_path)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T05:08:59.763821Z","iopub.status.busy":"2024-06-28T05:08:59.763147Z","iopub.status.idle":"2024-06-28T05:08:59.768565Z","shell.execute_reply":"2024-06-28T05:08:59.767626Z","shell.execute_reply.started":"2024-06-28T05:08:59.763787Z"},"trusted":true},"outputs":[],"source":["test_dataset = SamsumDataset(dataset['test'], tokenizer)\n","test_dataloader = DataLoader(test_dataset, batch_size=4, collate_fn=collator, shuffle=False)"]},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-28T05:09:00.358193Z","iopub.status.busy":"2024-06-28T05:09:00.357562Z","iopub.status.idle":"2024-06-28T05:09:00.396145Z","shell.execute_reply":"2024-06-28T05:09:00.395172Z","shell.execute_reply.started":"2024-06-28T05:09:00.358164Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["PeftModelForSeq2SeqLM(\n","  (base_model): LoraModel(\n","    (model): T5ForConditionalGeneration(\n","      (shared): Embedding(32128, 768)\n","      (encoder): T5Stack(\n","        (embed_tokens): Embedding(32128, 768)\n","        (block): ModuleList(\n","          (0): T5Block(\n","            (layer): ModuleList(\n","              (0): T5LayerSelfAttention(\n","                (SelfAttention): T5Attention(\n","                  (q): lora.Linear(\n","                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.05, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=768, out_features=32, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=32, out_features=768, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (k): Linear(in_features=768, out_features=768, bias=False)\n","                  (v): lora.Linear(\n","                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.05, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=768, out_features=32, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=32, out_features=768, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (o): Linear(in_features=768, out_features=768, bias=False)\n","                  (relative_attention_bias): Embedding(32, 12)\n","                )\n","                (layer_norm): T5LayerNorm()\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (1): T5LayerFF(\n","                (DenseReluDense): T5DenseGatedActDense(\n","                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                  (act): NewGELUActivation()\n","                )\n","                (layer_norm): T5LayerNorm()\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","          )\n","          (1-11): 11 x T5Block(\n","            (layer): ModuleList(\n","              (0): T5LayerSelfAttention(\n","                (SelfAttention): T5Attention(\n","                  (q): lora.Linear(\n","                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.05, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=768, out_features=32, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=32, out_features=768, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (k): Linear(in_features=768, out_features=768, bias=False)\n","                  (v): lora.Linear(\n","                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.05, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=768, out_features=32, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=32, out_features=768, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (o): Linear(in_features=768, out_features=768, bias=False)\n","                )\n","                (layer_norm): T5LayerNorm()\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (1): T5LayerFF(\n","                (DenseReluDense): T5DenseGatedActDense(\n","                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                  (act): NewGELUActivation()\n","                )\n","                (layer_norm): T5LayerNorm()\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","          )\n","        )\n","        (final_layer_norm): T5LayerNorm()\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (decoder): T5Stack(\n","        (embed_tokens): Embedding(32128, 768)\n","        (block): ModuleList(\n","          (0): T5Block(\n","            (layer): ModuleList(\n","              (0): T5LayerSelfAttention(\n","                (SelfAttention): T5Attention(\n","                  (q): lora.Linear(\n","                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.05, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=768, out_features=32, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=32, out_features=768, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (k): Linear(in_features=768, out_features=768, bias=False)\n","                  (v): lora.Linear(\n","                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.05, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=768, out_features=32, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=32, out_features=768, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (o): Linear(in_features=768, out_features=768, bias=False)\n","                  (relative_attention_bias): Embedding(32, 12)\n","                )\n","                (layer_norm): T5LayerNorm()\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (1): T5LayerCrossAttention(\n","                (EncDecAttention): T5Attention(\n","                  (q): lora.Linear(\n","                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.05, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=768, out_features=32, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=32, out_features=768, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (k): Linear(in_features=768, out_features=768, bias=False)\n","                  (v): lora.Linear(\n","                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.05, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=768, out_features=32, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=32, out_features=768, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (o): Linear(in_features=768, out_features=768, bias=False)\n","                )\n","                (layer_norm): T5LayerNorm()\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (2): T5LayerFF(\n","                (DenseReluDense): T5DenseGatedActDense(\n","                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                  (act): NewGELUActivation()\n","                )\n","                (layer_norm): T5LayerNorm()\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","          )\n","          (1-11): 11 x T5Block(\n","            (layer): ModuleList(\n","              (0): T5LayerSelfAttention(\n","                (SelfAttention): T5Attention(\n","                  (q): lora.Linear(\n","                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.05, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=768, out_features=32, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=32, out_features=768, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (k): Linear(in_features=768, out_features=768, bias=False)\n","                  (v): lora.Linear(\n","                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.05, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=768, out_features=32, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=32, out_features=768, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (o): Linear(in_features=768, out_features=768, bias=False)\n","                )\n","                (layer_norm): T5LayerNorm()\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (1): T5LayerCrossAttention(\n","                (EncDecAttention): T5Attention(\n","                  (q): lora.Linear(\n","                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.05, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=768, out_features=32, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=32, out_features=768, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (k): Linear(in_features=768, out_features=768, bias=False)\n","                  (v): lora.Linear(\n","                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.05, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=768, out_features=32, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=32, out_features=768, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (o): Linear(in_features=768, out_features=768, bias=False)\n","                )\n","                (layer_norm): T5LayerNorm()\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (2): T5LayerFF(\n","                (DenseReluDense): T5DenseGatedActDense(\n","                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                  (act): NewGELUActivation()\n","                )\n","                (layer_norm): T5LayerNorm()\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","          )\n","        )\n","        (final_layer_norm): T5LayerNorm()\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n","    )\n","  )\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["base_model.eval()\n","peft_model.eval()\n","ppo_model.eval()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T05:09:11.451052Z","iopub.status.busy":"2024-06-28T05:09:11.450255Z","iopub.status.idle":"2024-06-28T05:09:11.473895Z","shell.execute_reply":"2024-06-28T05:09:11.473137Z","shell.execute_reply.started":"2024-06-28T05:09:11.451019Z"},"trusted":true},"outputs":[],"source":["peft_model = peft_model.to(device)\n","ppo_model = ppo_model.to(device)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T05:43:19.479987Z","iopub.status.busy":"2024-06-28T05:43:19.479377Z","iopub.status.idle":"2024-06-28T05:43:58.531140Z","shell.execute_reply":"2024-06-28T05:43:58.530143Z","shell.execute_reply.started":"2024-06-28T05:43:19.479958Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluation Progress: 100%|██████████| 10/10 [00:39<00:00,  3.90s/it, PEFT Toxicity=0.249, RLHF Toxicity=0.112]\n"]}],"source":["max_eval_steps = 10\n","\n","base_toxicity_scores = []\n","rlhf_toxicity_scores = []\n","examples = []\n","\n","progress_bar = tqdm(total=max_eval_steps, desc=\"Evaluation Progress\", position=0, leave=True)\n","\n","for step, batch in enumerate(test_dataloader):\n","    if step >= max_eval_steps:\n","        break\n","\n","    input_ids = pad_sequence(batch['input_ids'], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n","    attention_mask = pad_sequence(batch['attention_mask'], batch_first=True, padding_value=0).to(device)\n","    dialogues = batch['query']\n","\n","    with torch.no_grad():\n","        # Generate summaries from base(PEFT) model\n","        base_summaries = peft_model.generate(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask,\n","        max_length=100,\n","        min_length=5,\n","        do_sample=True,\n","        temperature=1.2\n","        )\n","\n","        # Generate summaries from RLHF model\n","        rlhf_summaries = ppo_model.generate(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            max_length=100,\n","            min_length=5,\n","            do_sample=True,\n","            top_p=0.9,\n","            temperature=1.2\n","        )\n","\n","    base_summaries_text = [tokenizer.decode(s, skip_special_tokens=True) for s in base_summaries]\n","    rlhf_summaries_text = [tokenizer.decode(s, skip_special_tokens=True) for s in rlhf_summaries]\n","\n","    # Compute toxicity scores\n","    base_toxicities = reward_model.predict(base_summaries_text)['toxicity']\n","    rlhf_toxicities = reward_model.predict(rlhf_summaries_text)['toxicity']\n","\n","    base_toxicity_scores.extend(base_toxicities)\n","    rlhf_toxicity_scores.extend(rlhf_toxicities)\n","\n","    # Store examples\n","    for i in range(len(dialogues)):\n","        examples.append({\n","            'dialogue': dialogues[i],\n","            'peft_summary': base_summaries_text[i],\n","            'rlhf_summary': rlhf_summaries_text[i],\n","            'peft_toxicity': base_toxicities[i],\n","            'rlhf_toxicity': rlhf_toxicities[i]\n","        })\n","\n","    progress_bar.update(1)\n","    progress_bar.set_postfix({\n","        'PEFT Toxicity': f\"{sum(base_toxicities) / len(base_toxicities):.3f}\",\n","        'RLHF Toxicity': f\"{sum(rlhf_toxicities) / len(rlhf_toxicities):.3f}\"\n","    })\n","\n","# Close the progress bar\n","progress_bar.close()"]},{"cell_type":"markdown","metadata":{},"source":["### Quantitative evaluation"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T05:44:19.223800Z","iopub.status.busy":"2024-06-28T05:44:19.222908Z","iopub.status.idle":"2024-06-28T05:44:19.230823Z","shell.execute_reply":"2024-06-28T05:44:19.229733Z","shell.execute_reply.started":"2024-06-28T05:44:19.223755Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Percentage improvement in model summary toxicity:  -55.074720137557065 %\n"]}],"source":["final_toxicity_peft = sum(base_toxicities) / len(base_toxicities)\n","final_toxicity_rlhf = sum(rlhf_toxicities) / len(rlhf_toxicities)\n","\n","improvement = (final_toxicity_rlhf - final_toxicity_peft)/final_toxicity_peft * 100\n","print(\"Percentage improvement in model summary toxicity: \", improvement, \"%\")"]},{"cell_type":"markdown","metadata":{},"source":["### Qualitative evaluation"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T05:48:04.880411Z","iopub.status.busy":"2024-06-28T05:48:04.879760Z","iopub.status.idle":"2024-06-28T05:48:04.886235Z","shell.execute_reply":"2024-06-28T05:48:04.885341Z","shell.execute_reply.started":"2024-06-28T05:48:04.880380Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dialogue: Rita: I'm so bloody tired. Falling asleep at work. :-(\n","Tina: I know what you mean.\n","Tina: I keep on nodding off at my keyboard hoping that the boss doesn't notice..\n","Rita: The time just keeps on dragging on and on and on.... \n","Rita: I keep on looking at the clock and there's still 4 hours of this drudgery to go.\n","Tina: Times like these I really hate my work.\n","Rita: I'm really not cut out for this level of boredom.\n","Tina: Neither am I.\n","\n","PEFT Model Summary (Toxicity: 0.0034):\n","Rita is tired and she has snoozed. Ginna is snooying at her work. Rita hates her job, but says she is not ideal for hers. \n","\n","RLHF Model Summary (Toxicity: 0.0016):\n","Rita is very bored at work, she spends too much time looking at the clock. Tina thinks she dislikes her job, she's not cut out for it.\n","--------------------------------------------------\n"]}],"source":["import random\n","for i, example in enumerate(random.sample(examples, 1)):\n","    print(f\"Dialogue: {example['dialogue']}\")\n","    print(f\"\\nPEFT Model Summary (Toxicity: {example['peft_toxicity']:.4f}):\")\n","    print(example['peft_summary'])\n","    print(f\"\\nRLHF Model Summary (Toxicity: {example['rlhf_toxicity']:.4f}):\")\n","    print(example['rlhf_summary'])\n","    print(\"-\" * 50)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5297176,"sourceId":8807570,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
